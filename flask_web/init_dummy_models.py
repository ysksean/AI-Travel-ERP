import os
import torch
from transformers import ElectraConfig, ElectraForTokenClassification, AutoTokenizer

# ======================================================
# [ì„¤ì •] ëª¨ë¸ì´ ì €ì¥ë  ë¬¼ë¦¬ì  ìœ„ì¹˜ (ì¤‘ìš”!)
# ai_service.pyê°€ ë°”ë¼ë³´ëŠ” ê²½ë¡œì™€ ì¼ì¹˜ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.
# ======================================================
# í˜„ì¬: flask_web/init_dummy_models.py
# ëª©í‘œ: flask_web ìƒìœ„ í´ë”(travel)ì˜ models í´ë”
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # flask_web í´ë”
MODEL_SAVE_DIR = os.path.join(os.path.dirname(BASE_DIR), 'models')

# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
if not os.path.exists(MODEL_SAVE_DIR):
    os.makedirs(MODEL_SAVE_DIR)
    print(f"ğŸ“‚ ëª¨ë¸ ë©”ì¸ í´ë” ìƒì„±: {MODEL_SAVE_DIR}")


def create_dummy_models():
    print(f"ğŸš€ ë”ë¯¸ ëª¨ë¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì €ì¥ì†Œ: {MODEL_SAVE_DIR})")

    # --------------------------------------------------
    # 1. Tokenizer (í† í¬ë‚˜ì´ì €)
    # --------------------------------------------------
    # í† í¬ë‚˜ì´ì €ëŠ” êµ¬ì¡°ê°€ ë³µì¡í•˜ë¯€ë¡œ, ì‹¤ì œ KoELECTRA í† í¬ë‚˜ì´ì €ë¥¼
    # í•œ ë²ˆë§Œ ë‹¤ìš´ë¡œë“œí•´ì„œ ì €ì¥í•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
    print("\n[1/2] Tokenizer ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ ì¤‘...")
    try:
        tokenizer = AutoTokenizer.from_pretrained("monologg/koelectra-base-v3-discriminator")
        save_path = os.path.join(MODEL_SAVE_DIR, 'tokenizer')
        tokenizer.save_pretrained(save_path)
        print(f"  âœ… ì €ì¥ ì™„ë£Œ: {save_path}")
    except Exception as e:
        print(f"  âŒ ì‹¤íŒ¨ (ì¸í„°ë„· ì—°ê²° í™•ì¸ í•„ìš”): {e}")

    # --------------------------------------------------
    # 2. [M1] NER ëª¨ë¸ (KoELECTRA êµ¬ì¡°, ëœë¤ ê°€ì¤‘ì¹˜)
    # --------------------------------------------------
    print("\n[2/2] [M1] NER ëª¨ë¸(Dummy) ìƒì„± ì¤‘...")

    # ê»ë°ê¸°(ì„¤ì •)ë§Œ ì •ì˜í•©ë‹ˆë‹¤. (ê°€ë³ê²Œ ë§Œë“¤ê¸° ìœ„í•´ ë ˆì´ì–´ ìˆ˜ë¥¼ ì¤„ì„)
    config = ElectraConfig(
        vocab_size=35000,  # KoELECTRA ì–´íœ˜ í¬ê¸°
        hidden_size=64,  # (ë”ë¯¸ìš©) í¬ê¸° ëŒ€í­ ì¶•ì†Œ
        num_hidden_layers=2,  # (ë”ë¯¸ìš©) ë ˆì´ì–´ 2ê°œë§Œ
        num_attention_heads=4,
        intermediate_size=256,
        num_labels=7  # B-HOTEL, I-PRICE ë“± íƒœê·¸ ê°œìˆ˜ (0~6)
    )

    # ì„¤ì •ëŒ€ë¡œ ëª¨ë¸ ì´ˆê¸°í™” (ëœë¤ ê°’)
    model = ElectraForTokenClassification(config)

    # ì €ì¥
    save_path = os.path.join(MODEL_SAVE_DIR, 'koelectra_ner')
    model.save_pretrained(save_path)
    print(f"  âœ… ì €ì¥ ì™„ë£Œ: {save_path}")

    print("\nğŸ‰ ëª¨ë“  ë”ë¯¸ ëª¨ë¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ì´ì œ ai_service.pyë¥¼ ì‹¤í–‰í•˜ë©´ '{MODEL_SAVE_DIR}' ê²½ë¡œì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    create_dummy_models()